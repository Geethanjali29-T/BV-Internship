AI/ML Internship Projects
Welcome to my hands-on AI/ML internship repository! This collection includes fundamental machine learning algorithms implemented from scratch and using scikit-learn, each with clear objectives and supporting visualizations. Below is an overview of the tasks completed during the internship.New projects will be added regularly as I progress through the internship.

Projects Overview
✅ Task 1: Linear Regression (Simple & Multiple)
Objective:
->Predict house prices using both simple and multiple linear regression models.
Concepts Covered:
1)Simple Linear Regression from scratch
2)Multiple Linear Regression using NumPy
3)Gradient Descent Optimization
4)Loss Function: Mean Squared Error (MSE)
5)Data visualization using Matplotlib

✅ Task 2: Logistic Regression from Scratch
Objective:
->Classify diabetes risk using a binary classification approach derived from a regression dataset.
Concepts Covered:
1)Logistic Regression using the Sigmoid function
2)Binary Cross-Entropy Loss
3)Gradient Descent for classification
4)Model evaluation: Accuracy Score and Confusion Matrix

✅ Task 3: Decision Tree Classification
Objective:
->Predict Titanic survival outcomes using a mini dataset.
Concepts Covered:
1)Gini Index and Information Gain
2)Manual computation of Entropy and Decision Metrics
3)Building and visualizing Decision Trees using sklearn
4)Understanding decision paths and tree structure

✅ Task 4: Support Vector Machines (SVM)
Objective:
->Classify handwritten digits using various kernel-based SVM models.
Concepts Covered:
1)Linear, Polynomial, and RBF Kernel SVMs
2)Model training and prediction
3)Visualization of digit samples
4)Evaluation: Classification Reports and Confusion Matrices

✅ Task 5: K-Nearest Neighbors (KNN)
Objective:
->Classify Iris flower species using a custom-built KNN classifier.
Concepts Covered:
1)KNN algorithm from scratch (Euclidean distance)
2)Comparison with sklearn KNN classifier
3)Hyperparameter tuning: Finding the best value of K
4)Accuracy vs. K visualization

✅ Task 6: Spam Detection using Multinomial Naive Bayes
objective: 
->Build a basic spam detection model using the Multinomial Naive Bayes algorithm on a custom text dataset.
Concepts Covered:
1)Text preprocessing using Bag-of-Words (CountVectorizer)
2)Binary classification of text messages (Spam vs. Ham)
3)Model building using Multinomial Naive Bayes
4)Model evaluation with Accuracy and Classification Report
5)Testing on a custom message input

✅ Task 7: Customer Segmentation using K-Means
Objective: 
->Segment customers into distinct groups based on their purchasing behavior using K-Means Clustering.
Concepts Covered:
1)K-Means Clustering algorithm
2)Data Preprocessing using StandardScaler
3)Elbow Method to determine optimal number of clusters
4)Cluster Visualization using Seaborn
5)Customer profiling based on cluster assignments
